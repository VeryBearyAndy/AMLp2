{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f0b007-32ed-40fa-b350-1dc8a961b4c1",
   "metadata": {},
   "source": [
    "<H1>AML Project 2: Decision Trees, SVMs and Ensemble Learning</H1>\n",
    "<p1>Andrew J Markland, ajm259@uakron.edu</p1> <br>\n",
    "<p1>The University of Akron: CEPS : School of Computer Science</p1><br>\n",
    "<p1>Applied Machine Learning: CPSC:436:010</p1><br>\n",
    "<p1>Dr. Zhong-Hui Duan </p1><br><br>\n",
    "<p1>Abstract: The purpose of this assingment is to display understanding and untilization of Decesion tree, ensemble learning</p1><br>\n",
    "<p1>and SVM's through predicting the likelyhood of strokes through models that we will train with data retrived from NHANES</p1><br><br>\n",
    "<p1>Disclaimer** While this project is public in my public repository on github, I do not discourage others from using it as a </p1><br>\n",
    "<p1>reference for their own implementations, but the work written here is expressly written and owned by Andrew J Markland.</p1><br>\n",
    "<p1>I do not condone nor tolerate academic dishonesty, and should the question of plagerism arise derived from my works</p1><br>\n",
    "<p1>copies of this repository shall be promptly submitted to the assigning professor and the department of student affairs.</p1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50852820-a890-4a82-a2da-bc20444a2261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T00:26:14.874927500Z",
     "start_time": "2024-03-30T00:26:14.752064600Z"
    }
   },
   "outputs": [],
   "source": [
    "#includes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SEQN  Income  Sex  Age  Race  Edu  Diastolic    Systolic      Pulse  \\\n",
      "3267  4270    5.00    1   66     3  NaN  69.666667  125.666667  50.000000   \n",
      "120   1121     NaN    2   45     1  NaN  84.333333  124.666667  67.666667   \n",
      "1335  2336    5.00    1   36     3  NaN  79.000000  117.666667  61.666667   \n",
      "1981  2982    0.99    2   53     2  NaN  68.333333  106.000000  85.333333   \n",
      "3749  4754    1.80    2   49     4  NaN  87.000000  124.000000  75.000000   \n",
      "...    ...     ...  ...  ...   ...  ...        ...         ...        ...   \n",
      "2879  3881    2.22    1   54     4  NaN  62.000000   96.666667  74.333333   \n",
      "2616  3618     NaN    2   56     3  NaN  64.666667  104.000000  65.333333   \n",
      "2386  3387    0.95    1   62     4  NaN  76.000000  144.000000        NaN   \n",
      "502   1503    2.50    1   66     1  5.0  71.333333  131.333333  70.000000   \n",
      "341   1342    2.61    2   53     3  NaN  67.666667  111.333333  66.333333   \n",
      "\n",
      "       BMI  HDL  Trig  LDL  TCHOL  kidneys_eGFR  Diabetes  CurrentSmoker  \\\n",
      "3267  30.2   32   152  110    169     75.684047       2.0              2   \n",
      "120   25.8   57    75  146    220    110.521109       2.0              2   \n",
      "1335  25.1   49   228  163    251    114.287713       2.0              2   \n",
      "1981  29.6   59   129  115    198     95.537644       1.0              2   \n",
      "3749  46.2   89    57   87    190     78.485352       2.0              2   \n",
      "...    ...  ...   ...  ...    ...           ...       ...            ...   \n",
      "2879  26.1   67    91   92    177     74.847166       2.0              1   \n",
      "2616  29.3   60    94  125    205     95.315194       2.0              2   \n",
      "2386  18.9  139    35  148    299     20.090179       2.0              1   \n",
      "502   33.3   41   125  110    176     95.495861       2.0              2   \n",
      "341   25.2   72    73  108    196     94.011087       2.0              2   \n",
      "\n",
      "      isActive  isInsured  \n",
      "3267       1.0        1.0  \n",
      "120        2.0        2.0  \n",
      "1335       1.0        1.0  \n",
      "1981       2.0        1.0  \n",
      "3749       2.0        1.0  \n",
      "...        ...        ...  \n",
      "2879       2.0        1.0  \n",
      "2616       2.0        1.0  \n",
      "2386       1.0        1.0  \n",
      "502        2.0        1.0  \n",
      "341        2.0        1.0  \n",
      "\n",
      "[3273 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Data Manager\n",
    "    This cell will handle partitioning and cleaning the data and provide a hand-full of useful\n",
    "    variables that I can call on to test different data sets based on a partition of the test data, this is primarily \n",
    "    going to be used to streamline the testing phases and make data balancing and acquistion faster. \n",
    "\"\"\"\n",
    "class DataWrapper:\n",
    "    def __init__(self):\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "\n",
    "\n",
    "\n",
    "initialDataPD = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "def partitionAndBalance(dataObject):\n",
    "    global initialDataPD\n",
    "    X = initialDataPD.drop('stroke', axis=1)\n",
    "    y = initialDataPD['stroke']\n",
    "    dataObject.train_X, dataObject.test_X, dataObject.train_y, dataObject.test_y = train_test_split(X, y, test_size = 0.2)\n",
    "    balanceTrainData(dataObject.train_X, dataObject.train_y)\n",
    "    print(dataObject.train_X)\n",
    "    \n",
    "def balanceTrainData(train_X, train_y):\n",
    "    combinedDataDF = pd.DataFrame(train_X)\n",
    "    combinedDataDF['stroke'] = train_y\n",
    "    \"\"\"partition based on classes\"\"\"\n",
    "    strokeDF = combinedDataDF[combinedDataDF['stroke'] == 1]\n",
    "    noStrokeDF = combinedDataDF[combinedDataDF['stroke'] == 2]\n",
    "    \"\"\"clean up missing values\"\"\"\n",
    "    noStrokeDF.dropna()\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    imputedDF= imputer.fit_transform(strokeDF)\n",
    "    strokeDF = pd.DataFrame(imputedDF, columns=strokeDF.columns)\n",
    "    noStrokeDF = noStrokeDF.sample(n=len(strokeDF))\n",
    "    balancedDF = pd.concat([noStrokeDF, strokeDF])\n",
    "    train_X = balancedDF.drop('stroke', axis=1).values\n",
    "    train_y = balancedDF['stroke'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "data = DataWrapper()\n",
    "partitionAndBalance(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T00:58:20.790840900Z",
     "start_time": "2024-03-30T00:58:20.756840600Z"
    }
   },
   "id": "12c64942179275f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "67b519ef41c9fb52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
