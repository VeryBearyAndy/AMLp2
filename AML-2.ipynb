{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f0b007-32ed-40fa-b350-1dc8a961b4c1",
   "metadata": {},
   "source": [
    "<H1>AML Project 2: Decision Trees, SVMs and Ensemble Learning</H1>\n",
    "<p1>Andrew J Markland, ajm259@uakron.edu</p1> <br>\n",
    "<p1>The University of Akron: CEPS : School of Computer Science</p1><br>\n",
    "<p1>Applied Machine Learning: CPSC:436:010</p1><br>\n",
    "<p1>Dr. Zhong-Hui Duan </p1><br><br>\n",
    "<p1>Abstract: The purpose of this assingment is to display understanding and untilization of Decesion tree, ensemble learning</p1><br>\n",
    "<p1>and SVM's through predicting the likelyhood of strokes through models that we will train with data retrived from NHANES</p1><br><br>\n",
    "<p1>Disclaimer** While this project is public in my public repository on github, I do not discourage others from using it as a </p1><br>\n",
    "<p1>reference for their own implementations, but the work written here is expressly written and owned by Andrew J Markland.</p1><br>\n",
    "<p1>I do not condone nor tolerate academic dishonesty, and should the question of plagerism arise derived from my works</p1><br>\n",
    "<p1>copies of this repository shall be promptly submitted to the assigning professor and the department of student affairs.</p1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50852820-a890-4a82-a2da-bc20444a2261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T03:09:36.956125600Z",
     "start_time": "2024-04-02T03:09:34.962295900Z"
    }
   },
   "outputs": [],
   "source": [
    "#includes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data Manager\n",
    "    This cell will handle partitioning and cleaning the data and provide a hand-full of useful\n",
    "    variables that I can call on to test different data sets based on a partition of the test data, this is primarily \n",
    "    going to be used to streamline the testing phases and make data balancing and acquistion faster. \n",
    "\"\"\"\n",
    "class DataWrapper:\n",
    "    def __init__(self):\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "\n",
    "class finalWrapper:\n",
    "    def __init__(self):\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "\n",
    "initialDataPD = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "test_DF = pd.read_csv(\"NHANES_data_stroke_test4Students.csv\")\n",
    "test_DF = test_DF.drop(\"stroke\", axis=1)\n",
    "\n",
    "def partitionAndBalance(dataObject):\n",
    "    global initialDataPD\n",
    "    X = initialDataPD.drop('stroke', axis=1)\n",
    "    y = initialDataPD['stroke']\n",
    "    dataObject.train_x, dataObject.test_x, dataObject.train_y, dataObject.test_y = train_test_split(X, y, test_size = 0.2)\n",
    "    balanceTrainData(dataObject)\n",
    "    imputeMissingTestValues(dataObject)\n",
    "    #print(dataObject.train_X)\n",
    "    return dataObject\n",
    "    \n",
    "    \n",
    "def balanceTrainData(dataObject):\n",
    "    combinedDataDF = pd.DataFrame(dataObject.train_x)\n",
    "    combinedDataDF['stroke'] = dataObject.train_y\n",
    "    \"\"\"partition based on classes\"\"\"\n",
    "    strokeDF = combinedDataDF[combinedDataDF['stroke'] == 1]\n",
    "    noStrokeDF = combinedDataDF[combinedDataDF['stroke'] == 2]\n",
    "    \"\"\"clean up missing values\"\"\"\n",
    "    noStrokeDF = noStrokeDF.dropna()\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    imputedDF = imputer.fit_transform(strokeDF)\n",
    "    cleanStrokeDF = pd.DataFrame(imputedDF, columns=strokeDF.columns)\n",
    "    noStrokeDF = noStrokeDF.sample(n=len(cleanStrokeDF))\n",
    "    balancedDF = pd.concat([noStrokeDF, cleanStrokeDF])\n",
    "    dataObject.train_x = balancedDF.drop('stroke', axis=1)\n",
    "    dataObject.train_y = balancedDF['stroke']\n",
    "    \n",
    "def imputeMissingTestValues(dataObject):\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    imputedTestDF = imputer.fit_transform(dataObject.test_x)\n",
    "    dataObject.test_x = pd.DataFrame(imputedTestDF, columns=dataObject.test_x.columns)\n",
    "    \n",
    "def dropRows(dataObject, rows):\n",
    "    for row in rows:\n",
    "        dataObject.test_x.drop(row, axis=1)\n",
    "        dataObject.train_x.drop(row, axis=1)\n",
    "        \n",
    "def scaleData(dataObject):\n",
    "    scaler = StandardScaler()\n",
    "    trainScaled = scaler.fit_transform(dataObject.train_x)\n",
    "    testScaled = scaler.transform(dataObject.test_x)\n",
    "    dataObject.test_x = pd.DataFrame(testScaled, columns=dataObject.test_x.columns)\n",
    "    dataObject.train_x = pd.DataFrame(trainScaled, columns=dataObject.train_x.columns)\n",
    "\n",
    "def imputeMissingValuesDataFrame(data):\n",
    "    imputer = KNNImputer(n_neighbors = 3)\n",
    "    cleanData = imputer.fit_transform(data)\n",
    "    data = pd.DataFrame(cleanData, columns=data.columns)\n",
    "    return data\n",
    "\n",
    "def dropRowsDataframe(data, rows):\n",
    "    for row in rows:\n",
    "        data.drop(row, axis=1)\n",
    "    return data\n",
    "\n",
    "def cutParticipantID(data):\n",
    "    patientIds = pd.DataFrame(data[\"ParticipantID\"], columns=[\"ParticipantID\"])\n",
    "    data.drop(\"ParticipantID\", axis=1);\n",
    "    return patientIds\n",
    "    \n",
    "def balanceFinalWrapper(Fwrapper):\n",
    "    #load data and separate\n",
    "    strokeDF = initialDataPD[initialDataPD['stroke'] == 1]\n",
    "    noStrokeDF = initialDataPD[initialDataPD['stroke'] == 2]\n",
    "    #clean the data\n",
    "    noStrokeDF = noStrokeDF.dropna()\n",
    "    imputer = KNNImputer(n_neighbors = 3)\n",
    "    cleanStroke = imputer.fit_transform(strokeDF)\n",
    "    strokeDF = pd.DataFrame(cleanStroke, columns=strokeDF.columns)\n",
    "    noStrokeDF = noStrokeDF.sample(n=len(strokeDF))\n",
    "    #join the data back together\n",
    "    FTrainDF = pd.concat([strokeDF, noStrokeDF])\n",
    "    #set the training data \n",
    "    Fwrapper.train_x = FTrainDF.drop(\"stroke\", axis=1)\n",
    "    Fwrapper.train_y = FTrainDF[\"stroke\"]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T00:31:28.766149200Z",
     "start_time": "2024-04-03T00:31:28.744146700Z"
    }
   },
   "id": "12c64942179275f6"
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684981684981685\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random Forest run,\n",
    "    This cell is the testing of the random forest model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#getting a random distribution of data and balancing it\n",
    "rf_dataObject = DataWrapper()\n",
    "rf_dataObject = partitionAndBalance(rf_dataObject)\n",
    "\n",
    "noise = [\"Income\", \"Sex\", \"Race\", \"Edu\", \"Diabetes\", \"isInsured\"]\n",
    "dropRows(rf_dataObject, noise)\n",
    "\n",
    "# initializing the random forest\n",
    "randForest = RandomForestClassifier(n_estimators = 1000, max_depth = 12, min_samples_split=20, min_samples_leaf=15, max_features=5)\n",
    "\n",
    "randForest.fit(rf_dataObject.train_x, rf_dataObject.train_y)\n",
    "\n",
    "prediction = randForest.predict(rf_dataObject.test_x)\n",
    "accuracy = accuracy_score(rf_dataObject.test_y, prediction)\n",
    "print(accuracy)\n",
    "\n",
    "def getForestRun(accuracyList):\n",
    "    #getting a random distribution of data and balancing it \n",
    "    rf_dataObject = DataWrapper()\n",
    "    rf_dataObject = partitionAndBalance(rf_dataObject)\n",
    "    \n",
    "    noise = [\"Income\", \"Sex\", \"Race\", \"Edu\", \"Diabetes\", \"isInsured\"]\n",
    "    dropRows(rf_dataObject, noise)\n",
    "    rf_dataObject.train_x.drop(\"ParticipantID\", axis=1)\n",
    "    rf_dataObject.test_x.drop(\"ParticipantID\", axis=1)\n",
    "\n",
    "    # initializing the random forest\n",
    "    randForest = RandomForestClassifier(n_estimators = 1000, max_depth = 12, min_samples_split=20, min_samples_leaf=15, max_features=5)\n",
    "\n",
    "    randForest.fit(rf_dataObject.train_x, rf_dataObject.train_y)\n",
    "\n",
    "    prediction = randForest.predict(rf_dataObject.test_x)\n",
    "    accuracy = accuracy_score(rf_dataObject.test_y, prediction)\n",
    "    accuracyList.append(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T00:10:32.844247700Z",
     "start_time": "2024-04-03T00:10:31.408174300Z"
    }
   },
   "id": "67b519ef41c9fb52"
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6532356532356532\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " Gradient Boosted Tree\n",
    "    this cell is for testing the gradient boosted tree model\n",
    "\"\"\"\n",
    "\n",
    "#getting a Random Distribution of data and balancing it\n",
    "grad_dataObject = partitionAndBalance(DataWrapper())\n",
    "\n",
    "noise = [\"Income\", \"Sex\", \"Race\", \"Edu\", \"Diabetes\", \"BMI\"]\n",
    "dropRows(grad_dataObject, noise)\n",
    "\n",
    "grad_dataObject.test_x.drop(\"ParticipantID\", axis=1)\n",
    "grad_dataObject.train_x.drop(\"ParticipantID\", axis=1)\n",
    "\n",
    "gradTree = GradientBoostingClassifier(n_estimators=500, max_depth=10, min_samples_split=20, learning_rate=0.1, min_samples_leaf=15, max_features=5)\n",
    "gradTree.fit(grad_dataObject.train_x, grad_dataObject.train_y)\n",
    "\n",
    "prediction = gradTree.predict(grad_dataObject.test_x)\n",
    "accuracy = accuracy_score(grad_dataObject.test_y, prediction)\n",
    "print(accuracy)\n",
    "\n",
    "def getGradRun(accuracyList):\n",
    "    #getting a Random Distribution of data and balancing it\n",
    "    grad_dataObject = partitionAndBalance(DataWrapper())\n",
    "    #noise = [\"Income\", \"Sex\", \"Race\", \"Edu\", \"Diabetes\"]\n",
    "    dropRows(grad_dataObject, noise)\n",
    "    grad_dataObject.test_x.drop(\"ParticipantID\", axis=1)\n",
    "    grad_dataObject.train_x.drop(\"ParticipantID\", axis=1)\n",
    "\n",
    "    gradTree = GradientBoostingClassifier(n_estimators=500, max_depth=10, min_samples_split=20, learning_rate=0.1, min_samples_leaf=15, max_features=5)\n",
    "    gradTree.fit(grad_dataObject.train_x, grad_dataObject.train_y)\n",
    "\n",
    "    prediction = gradTree.predict(grad_dataObject.test_x)\n",
    "    accuracy = accuracy_score(grad_dataObject.test_y, prediction)\n",
    "    accuracyList.append(accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:45:04.016046400Z",
     "start_time": "2024-04-02T23:45:03.454910700Z"
    }
   },
   "id": "f8766bbefae8f682"
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6874236874236874\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Support Vector Machine\n",
    "    This cell is for testing the support Vector Machine model\n",
    "\"\"\"\n",
    "\n",
    "svm_data = partitionAndBalance(DataWrapper())\n",
    "SVM = SVC(kernel = 'rbf', C=.6, gamma=0.001)\n",
    "scaleData(svm_data)\n",
    "SVM.fit(svm_data.train_x, svm_data.train_y)\n",
    "\n",
    "prediction = SVM.predict(svm_data.test_x)\n",
    "\n",
    "accuracy = accuracy_score(svm_data.test_y, prediction)\n",
    "print(accuracy)\n",
    "\n",
    "def getSVMrun(accuracyList):\n",
    "    svm_data = partitionAndBalance(DataWrapper())\n",
    "    SVM = SVC(kernel = 'rbf', C=1, gamma=(1/18))\n",
    "    svm_data.train_x.drop(\"ParticipantID\", axis=1)\n",
    "    svm_data.test_x.drop(\"ParticipantID\", axis=1)\n",
    "    scaleData(svm_data)\n",
    "    SVM.fit(svm_data.train_x, svm_data.train_y)\n",
    "\n",
    "    prediction = SVM.predict(svm_data.test_x)\n",
    "\n",
    "    accuracy.append(accuracy_score(svm_data.test_y, prediction))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T23:14:34.500117100Z",
     "start_time": "2024-04-02T23:14:34.389090100Z"
    }
   },
   "id": "58bbf0bfb012c2c7"
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6886446886446884\n",
      "0.6166056166056166\n",
      "0.7509157509157509\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing cell\n",
    "  this cell is mostly just to run 100 runs of each model with random partitions of\n",
    "  the test data to see average performance across the runs\n",
    "\"\"\"\n",
    "\n",
    "accuracy = []\n",
    "for x in range(100):\n",
    "    getForestRun(accuracy)\n",
    "\n",
    "print(sum(accuracy)/len(accuracy))\n",
    "print(min(accuracy))\n",
    "print(max(accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T00:33:56.630214Z",
     "start_time": "2024-04-03T00:31:32.198115600Z"
    }
   },
   "id": "f69e472809b35dff"
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x\n",
      "      ParticipantID  Income  Sex   Age  Race       Edu  Diastolic    Systolic  \\\n",
      "0            1879.0    0.87  2.0  62.0   4.0  3.333333  92.333333  168.000000   \n",
      "1            1905.0    1.52  2.0  69.0   3.0  2.333333  99.000000  130.666667   \n",
      "2            1908.0    1.52  1.0  52.0   4.0  3.333333  87.666667  127.666667   \n",
      "3            1921.0    0.06  2.0  64.0   4.0  2.333333  65.666667  110.333333   \n",
      "4            1948.0    1.00  2.0  62.0   3.0  3.000000  75.333333  158.666667   \n",
      "...             ...     ...  ...   ...   ...       ...        ...         ...   \n",
      "3596         4601.0    0.56  2.0  40.0   1.0  1.000000  58.000000  110.666667   \n",
      "3582         4587.0    0.02  2.0  35.0   1.0  3.000000  63.333333  106.000000   \n",
      "191          1192.0    0.40  1.0  49.0   6.0  4.000000  77.333333  112.666667   \n",
      "3947         4952.0    1.74  2.0  32.0   1.0  4.000000  75.333333  108.000000   \n",
      "3528         4533.0    1.36  1.0  45.0   7.0  2.000000  72.000000  110.666667   \n",
      "\n",
      "          Pulse        BMI   HDL   Trig    LDL  TCHOL  kidneys_eGFR  Diabetes  \\\n",
      "0     61.333333  43.800000  45.0  149.0  170.0  244.0     62.942432       2.0   \n",
      "1     54.333333  39.400000  48.0   59.0   57.0  119.0     54.944973       1.0   \n",
      "2     66.000000  32.400000  36.0  143.0  149.0  212.0     54.362228       2.0   \n",
      "3     77.000000  31.933333  39.0   96.0  100.0  158.0     96.734724       2.0   \n",
      "4     90.000000  24.000000  77.0   81.0  152.0  245.0     52.673713       2.0   \n",
      "...         ...        ...   ...    ...    ...    ...           ...       ...   \n",
      "3596  74.000000  25.200000  48.0  293.0  132.0  239.0    123.166458       2.0   \n",
      "3582  86.000000  26.400000  47.0  214.0  105.0  195.0    117.612995       2.0   \n",
      "191   68.000000  27.000000  46.0   83.0  118.0  181.0    101.972858       2.0   \n",
      "3947  62.000000  29.000000  46.0  123.0  167.0  238.0     73.209776       2.0   \n",
      "3528  64.000000  24.100000  50.0   52.0  121.0  181.0    110.805614       2.0   \n",
      "\n",
      "      CurrentSmoker  isActive  isInsured  \n",
      "0               1.0       2.0        1.0  \n",
      "1               2.0       2.0        1.0  \n",
      "2               1.0       1.0        2.0  \n",
      "3               1.0       2.0        1.0  \n",
      "4               1.0       2.0        1.0  \n",
      "...             ...       ...        ...  \n",
      "3596            1.0       2.0        2.0  \n",
      "3582            2.0       2.0        2.0  \n",
      "191             1.0       2.0        2.0  \n",
      "3947            2.0       2.0        1.0  \n",
      "3528            2.0       2.0        2.0  \n",
      "\n",
      "[270 rows x 19 columns]\n",
      "train_y\n",
      "      stroke\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "...      ...\n",
      "3596     2.0\n",
      "3582     2.0\n",
      "191      2.0\n",
      "3947     2.0\n",
      "3528     2.0\n",
      "\n",
      "[270 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Random Forests Final Run\n",
    "    ***Discrete Values***\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T00:29:36.634945100Z",
     "start_time": "2024-04-03T00:29:36.596945400Z"
    }
   },
   "id": "d93024ca0dc9d629"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1fa5d086a6a91d86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
