{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f0b007-32ed-40fa-b350-1dc8a961b4c1",
   "metadata": {},
   "source": [
    "<H1>AML Project 2: Decision Trees, SVMs and Ensemble Learning</H1>\n",
    "<p1>Andrew J Markland, ajm259@uakron.edu</p1> <br>\n",
    "<p1>The University of Akron: CEPS : School of Computer Science</p1><br>\n",
    "<p1>Applied Machine Learning: CPSC:436:010</p1><br>\n",
    "<p1>Dr. Zhong-Hui Duan </p1><br><br>\n",
    "<p1>Abstract: The purpose of this assingment is to display understanding and untilization of Decesion tree, ensemble learning</p1><br>\n",
    "<p1>and SVM's through predicting the likelyhood of strokes through models that we will train with data retrived from NHANES</p1><br><br>\n",
    "<p1>Disclaimer** While this project is public in my public repository on github, I do not discourage others from using it as a </p1><br>\n",
    "<p1>reference for their own implementations, but the work written here is expressly written and owned by Andrew J Markland.</p1><br>\n",
    "<p1>I do not condone nor tolerate academic dishonesty, and should the question of plagerism arise derived from my works</p1><br>\n",
    "<p1>copies of this repository shall be promptly submitted to the assigning professor and the department of student affairs.</p1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "50852820-a890-4a82-a2da-bc20444a2261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T02:17:53.218521700Z",
     "start_time": "2024-04-01T02:17:53.205509700Z"
    }
   },
   "outputs": [],
   "source": [
    "#includes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SEQN  Income  Sex   Age  Race       Edu  Diastolic    Systolic  \\\n",
      "0    4592.0    0.40  2.0  63.0   1.0  2.000000  76.000000  127.333333   \n",
      "1    2025.0    0.86  2.0  66.0   7.0  3.000000  81.666667  125.666667   \n",
      "2    4997.0    2.64  2.0  36.0   1.0  1.000000  62.666667  105.333333   \n",
      "3    3866.0    2.65  2.0  73.0   3.0  1.666667  85.666667  121.000000   \n",
      "4    3704.0    4.25  2.0  65.0   3.0  5.000000  76.000000  115.333333   \n",
      "..      ...     ...  ...   ...   ...       ...        ...         ...   \n",
      "814  1315.0    5.00  2.0  60.0   3.0  4.000000  59.333333  101.333333   \n",
      "815  2718.0    0.74  2.0  44.0   2.0  3.000000  80.000000  136.666667   \n",
      "816  2501.0    3.39  1.0  63.0   6.0  4.000000  73.333333  154.000000   \n",
      "817  3993.0    2.45  1.0  48.0   4.0  3.000000  89.333333  150.333333   \n",
      "818  4863.0    4.21  1.0  71.0   2.0  5.000000  68.000000  158.000000   \n",
      "\n",
      "         Pulse   BMI   HDL   Trig    LDL  TCHOL  kidneys_eGFR  Diabetes  \\\n",
      "0    80.000000  38.3  47.0  145.0  127.0  203.0     83.002277       2.0   \n",
      "1    56.555556  28.8  61.0  107.0  152.0  236.0     84.013799       2.0   \n",
      "2    60.000000  29.9  46.0  102.0  107.0  173.0    121.386451       2.0   \n",
      "3    93.666667  49.6  46.0  253.0  158.0  246.0     79.198857       2.0   \n",
      "4    74.000000  39.6  63.0  184.0   84.0  184.0     81.976239       2.0   \n",
      "..         ...   ...   ...    ...    ...    ...           ...       ...   \n",
      "814  59.666667  46.9  40.0  187.0   71.0  137.0     61.509312       3.0   \n",
      "815  64.000000  32.2  85.0   76.0  106.0  206.0     97.855524       2.0   \n",
      "816  59.666667  24.0  65.0   96.0   87.0  171.0     97.638610       3.0   \n",
      "817  49.333333  34.3  41.0   82.0  165.0  225.0    110.004043       2.0   \n",
      "818  78.000000  29.4  47.0  148.0   98.0  175.0     87.786610       3.0   \n",
      "\n",
      "     CurrentSmoker  isActive  isInsured  \n",
      "0              2.0       2.0        2.0  \n",
      "1              2.0       2.0        1.0  \n",
      "2              2.0       2.0        2.0  \n",
      "3              2.0       2.0        1.0  \n",
      "4              2.0       2.0        1.0  \n",
      "..             ...       ...        ...  \n",
      "814            2.0       2.0        1.0  \n",
      "815            1.0       1.0        1.0  \n",
      "816            1.0       2.0        1.0  \n",
      "817            2.0       2.0        1.0  \n",
      "818            2.0       2.0        1.0  \n",
      "\n",
      "[819 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Data Manager\n",
    "    This cell will handle partitioning and cleaning the data and provide a hand-full of useful\n",
    "    variables that I can call on to test different data sets based on a partition of the test data, this is primarily \n",
    "    going to be used to streamline the testing phases and make data balancing and acquistion faster. \n",
    "\"\"\"\n",
    "class DataWrapper:\n",
    "    def __init__(self):\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "\n",
    "\n",
    "\n",
    "initialDataPD = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "def partitionAndBalance(dataObject):\n",
    "    global initialDataPD\n",
    "    X = initialDataPD.drop('stroke', axis=1)\n",
    "    y = initialDataPD['stroke']\n",
    "    dataObject.train_x, dataObject.test_x, dataObject.train_y, dataObject.test_y = train_test_split(X, y, test_size = 0.2)\n",
    "    balanceTrainData(dataObject)\n",
    "    imputeMissingTestValues(dataObject)\n",
    "    #print(dataObject.train_X)\n",
    "    return dataObject\n",
    "    \n",
    "    \n",
    "def balanceTrainData(dataObject):\n",
    "    combinedDataDF = pd.DataFrame(dataObject.train_x)\n",
    "    combinedDataDF['stroke'] = dataObject.train_y\n",
    "    \"\"\"partition based on classes\"\"\"\n",
    "    strokeDF = combinedDataDF[combinedDataDF['stroke'] == 1]\n",
    "    noStrokeDF = combinedDataDF[combinedDataDF['stroke'] == 2]\n",
    "    \"\"\"clean up missing values\"\"\"\n",
    "    noStrokeDF = noStrokeDF.dropna()\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    imputedDF = imputer.fit_transform(strokeDF)\n",
    "    cleanStrokeDF = pd.DataFrame(imputedDF, columns=strokeDF.columns)\n",
    "    noStrokeDF = noStrokeDF.sample(n=len(cleanStrokeDF))\n",
    "    balancedDF = pd.concat([noStrokeDF, cleanStrokeDF])\n",
    "    dataObject.train_x = balancedDF.drop('stroke', axis=1)\n",
    "    dataObject.train_y = balancedDF['stroke']\n",
    "    \n",
    "def imputeMissingTestValues(dataObject):\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    imputedTestDF = imputer.fit_transform(dataObject.test_x)\n",
    "    dataObject.test_x = pd.DataFrame(imputedTestDF, columns=dataObject.test_x.columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:47:01.185975800Z",
     "start_time": "2024-04-01T00:47:01.117462700Z"
    }
   },
   "id": "12c64942179275f6"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7350427350427351\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random Forest run,\n",
    "    This cell is the testing of the random forest model\n",
    "\"\"\"\n",
    "\n",
    "#getting a random distribution of data and balancing it\n",
    "rf_dataObject = DataWrapper()\n",
    "rf_dataObject = partitionAndBalance(rf_dataObject)\n",
    "\n",
    "# initializing the random forest\n",
    "randForest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "randForest.fit(rf_dataObject.train_x, rf_dataObject.train_y)\n",
    "\n",
    "prediction = randForest.predict(rf_dataObject.test_x)\n",
    "accuracy = accuracy_score(rf_dataObject.test_y, prediction)\n",
    "print(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:10:02.951139600Z",
     "start_time": "2024-04-01T02:10:02.743587600Z"
    }
   },
   "id": "67b519ef41c9fb52"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:22:15.129987Z",
     "start_time": "2024-04-01T02:22:15.119974200Z"
    }
   },
   "id": "f8766bbefae8f682"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "58bbf0bfb012c2c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
